---
title: "Quality Assessment of MODIS IV data"
author: "AJ Perez-Luque (@ajpelu)"
date: "2017 March"
output:  
  md_document:
    toc: true
    variant: markdown_github
---
  
# Filter data 
```{r wd, echo=FALSE}
#---------------------------------
machine <- 'ajpelu'
# machine <- 'ajpeluLap'
di <- paste('/Users/', machine, '/Dropbox/phd/phd_repos/qpyr_modis_resilience', sep='')
#---------------------------------
```

```{r packages, warning=FALSE, message=FALSE}
library("tidyverse")
library("knitr")
library("binaryLogic")
source(paste0(di,"/script/R/getComposite.R"))
```


```{r}
# Read data
rawdata <- read.csv(file=paste(di, "/data_raw/evi/iv_qp_raw_qa_2017.csv", sep= ""), header = TRUE, sep = ',')
```

## Prepare Raw Data
* Raw data come from GEE script (see [`/script/GEE/get_iv_modis.qp.js`](/script/GEE/get_iv_modis_qp.js)

* Date:
    + Get date of the image (from hdf title, system.index) 
    + Store as date (date format) and create new variable for year 

* Select and rename variables of interest 

```{r}
raw <- rawdata %>% 
  mutate(
    # Date
    date = as.Date(substr(system.index,1,10), format = "%Y_%m_%d"),
    # date2 = as.Date(substr(system.index,1,10), format = "%Y_%m_%d"),
    year = lubridate::year(date), 
    
    # GEE index
    gee_index = stringr::str_replace(
      substr(system.index,22, nchar(as.character(system.index))),
    pattern = '_', "")) %>% 
    # test = ifelse(date == date2, 0, 1))
  dplyr::select(doy = DayOfYear, evi = EVI, ndvi = NDVI, summQA = SummaryQA, iv_malla_modi_id,
                pop, date, year, gee_index, lat, long, 
                qa_quality, qa_use, qa_aerosol, qa_adj_cloud, 
                qa_atmos, qa_mix_cloud, qa_landwater, qa_snow, qa_shadow)
```
    
## Some metadata of the time series 
* Temporal range of the time series 

```{r}
# Get temporal range of the data
# Start date
unique(min(as.Date(raw$date)))

# End date 
unique(max(as.Date(raw$date)))
```

* Number of images per year 
```{r}
# See n of images per year and per pixel 
n_images_pixel <- raw %>% 
  mutate(year = lubridate::year(date)) %>% 
  group_by(year) %>%
  summarise(n = n(),
            n_pixel = n()/length(unique(iv_malla_modi_id)))

kable(n_images_pixel)
```

* Summary table of layer summaryQA 

```{r}
# Table of QA
raw %>% group_by(summQA) %>% 
  summarise(npixels = n()) %>% 
  mutate(freq = round((npixels / sum(npixels)*100),2),
         QA = plyr::mapvalues(summQA, c(0, 1, 2, 3), c("Good Data", "Marginal data", "Snow/Ice", "Cloudy"))) %>% 
  kable() 
```

### QA 
* Explore temporal distribution of QA

```{r, message=FALSE, warning=FALSE}
qadate <- raw %>% 
  group_by(date, summQA) %>% 
  count(date, summQA) %>% 
  mutate(freq = round((n / sum(n))*100, 2),
         QA = plyr::mapvalues(summQA, c(0, 1, 2, 3), 
                              c("Good Data", "Marginal data", "Snow/Ice", "Cloudy"))) 
qadate %>% 
  ggplot(aes(x=as.Date(date), y=freq, fill=QA)) + 
  geom_bar(stat = 'identity', position='fill') + 
#  facet_wrap(~QA, ncol=1) + 
  theme_bw() +
  scale_x_date(date_labels = "%Y %d")
```


## QA detailed 
* Only explore the marginal data


```{r} 
decodeQA <- function(x, nb){
  bit <- intToBits(x)
  paste(tail(rev(as.integer(bit)), nb), collapse="")}

decodeQAv <- Vectorize(decodeQA)


marginal <- raw %>% filter(summQA == 1) 
```


### Quality 
```{r}
marginal %>% 
  mutate(qa_quality_dec = decodeQAv(qa_quality, nb=2)) %>% 
  group_by(qa_quality_dec) %>% 
  summarise(n = n()) %>% 
  mutate(freq = round(n / sum (n)*100,2)) %>% 
  kable()
```


### Quality usefulness
* All data
```{r}
# See https://lpdaac.usgs.gov/sites/default/files/public/product_documentation/mod13_user_guide.pdf 
raw %>% 
  mutate(qa_use_dec = decodeQAv(qa_use, nb=4)) %>% 
  group_by(qa_use_dec) %>% 
  summarise(n = n()) %>% 
  mutate(freq = round(n / sum (n)*100,2)) %>% 
  kable()
```

* Marginal data 
```{r}
marginal %>% 
  mutate(qa_use_dec = decodeQAv(qa_use, nb=4)) %>% 
  group_by(qa_use_dec) %>% 
  summarise(n = n()) %>% 
  mutate(freq = round(n / sum (n)*100,2)) %>% 
  kable() 
```

### Aerosol 
```{r}
marginal %>% 
  mutate(qa_aerosol_dec = decodeQAv(qa_aerosol, nb=2)) %>% 
  group_by(qa_aerosol_dec) %>% 
  summarise(n = n()) %>% 
  mutate(freq = round(n / sum (n)*100,2)) %>% 
  kable()
```

* Only the 7.02 % of the pixels marked as 'Marginal data' contain high concentration of Aerosols. 

### Clouds 
```{r}
# Adjacents
marginal %>% 
  mutate(qa_adj_cloud_dec = decodeQAv(qa_adj_cloud, nb=1)) %>% 
  group_by(qa_adj_cloud_dec) %>% 
  summarise(n = n()) %>% 
  mutate(freq = round(n / sum (n)*100,2)) %>% 
  kable()

# Mixed
marginal %>% 
  mutate(qa_mix_cloud_dec = decodeQAv(qa_mix_cloud, nb=1)) %>% 
  group_by(qa_mix_cloud_dec) %>% 
  summarise(n = n()) %>% 
  mutate(freq = round(n / sum (n)*100,2)) %>% 
  kable()
```

* All the pixel marked as 'Marginal data' do not contain mixed cloud.
* We have to consider the Adjacent clouds 

### Snow 
```{r}
marginal %>% 
  mutate(qa_snow_dec = decodeQAv(qa_snow, nb=1)) %>% 
  group_by(qa_snow_dec) %>% 
  summarise(n = n()) %>% 
  mutate(freq = round(n / sum (n)*100,2)) %>% 
  kable()
```

* All the pixel marked as 'Marginal data' do not contain snow or ice. 

### Shadow
```{r}
marginal %>% 
  mutate(qa_shadow_dec = decodeQAv(qa_shadow, nb=1)) %>% 
  group_by(qa_shadow_dec) %>% 
  summarise(n = n()) %>% 
  mutate(freq = round(n / sum (n)*100,2)) %>% 
  kable()
```

* We have to consider the shadow 

### Filter 
We applied customized filter based on Reyes-Díez et al. 2015. 

* Creamos una variable nueva, llamada `filtered`. Aquellos pixeles con *Good Data* le asignamos valor `90`. Los *Snow/Ice* y los *Cloudy* le asignamos valor `99`. Para los *Marginal Data* miramos la calidad. En concreto previamente hemos analizado la cantidad de aerosoles, la de nubes y la de sombras (ver mas arriba). La forma de proceder es la siguiente: 
    + Si tiene alta concentración de aerosoles, marcamos el pixel con 1. 
    + Si tiene nubes adjacentes, marcamos el pixel con 1.
    + Si tiene sombra, marcamos el pixel con 1. 
    + Al final, creamos una variable llamada `f_sum` con la suma de esos tres filtros. Si en alguno de los tres filtros se da la condición 1, es decir `f_sum > = 1`, entonces, le asignamos el valor `99` en la variable filtered.  


```{r}
rawfilter <- raw %>% 
  mutate(f_aerosol = ifelse(decodeQAv(qa_aerosol, nb=2) == '11', 'Aerosol (high)', 'OK'),
         f_cloud_a = ifelse(decodeQAv(qa_adj_cloud, nb=1) == '1', 'Clouds: adjacent', 'OK'),
         f_shadow = ifelse(decodeQAv(qa_shadow, nb=1) == '1', 'Shadow','OK'),
         # as integer
         f_aerosoli = ifelse(f_aerosol == 'OK', 0, 1),
         f_cloud_ai = ifelse(f_cloud_a == 'OK', 0, 2),
         f_shadowi = ifelse(f_shadow == 'OK', 0, 4)) 

rawfilter <- rawfilter %>% 
  mutate(f_sum = f_aerosoli + f_cloud_ai + f_shadowi,
         filtered = ifelse(summQA == 0, 90, 
                           ifelse(summQA %in% c(2,3), 99, f_sum)), 
         
         filtered_qa = plyr::mapvalues(filtered, 
                                       c(0, 1, 2, 3, 4, 5, 6, 7, 90, 99, NA),
                                       c("Others", "Aerosol",
                                         "Clouds adj", "Aerosol + Clouds adj",
                                         "Shadow", "Aerosol + Shadow", 
                                         "Clouds adj + Shadow", 
                                         "Aerosol + Clouds adj + Shadow",
                                         "Good Data", "Snow / Ice or Cloudy", "NA")),
         mes = lubridate::month(date))

rawfilter %>% group_by(filtered_qa) %>% 
  summarise(npixels = n()) %>% 
  mutate(freq = round((npixels / sum(npixels)*100),2)) %>% 
  kable() 
```

* According to Reyes-Díez et al. (2015) we must consider the shadow in the mountain, but we can discard the filter of adjacent clouds. On the other hand, the use of EVI mean is highly stable under the use of any filter (see Reyes-Díez et al. 2015). 

```{r}
rawfilter <- rawfilter %>% 
  mutate(filtered_2 = ifelse(filtered %in% c(0,1,2,3), 90, filtered),
         filtered_2_qa = plyr::mapvalues(filtered_2, 
                                       c(4, 5, 6, 7, 90, 99, NA),
                                       c("Shadow", "Aerosol + Shadow", 
                                         "Clouds adj + Shadow", 
                                         "Aerosol + Clouds adj + Shadow",
                                         "Good Data", "Snow / Ice or Cloudy", "NA")))


rawfilter %>% group_by(filtered_2_qa) %>% 
  summarise(npixels = n()) %>% 
  mutate(freq = round((npixels / sum(npixels)*100),2)) %>% 
  kable()

```

We have to explore the temporal distribution of the filtered data (especially for Shadow)

```{r}
sombras <- c("Shadow", "Aerosol + Shadow","Clouds adj + Shadow", "Aerosol + Clouds adj + Shadow") 
sombras_n <- c(4, 5, 6, 7)
                                         
# Shadow 
rawfilter %>% filter(filtered_2 %in% sombras_n) %>% group_by(mes) %>% 
  summarise(n=n()) %>% 
  mutate(freq = round((n  / sum(n )*100),2)) %>% 
  ggplot(aes(x=as.factor(mes), y=n)) + 
  geom_bar(stat='identity') +
  geom_text(aes(label=freq, size=3, vjust=-.25)) + 
  theme_bw() + 
  theme(legend.position = 'none') + 
  xlab('month') + 
  ylab('# Images with shadow')
```

Now for Ice / Cloudy 
```{r}
# "Snow / Ice or Cloudy" (99)
                                         
# Shadow 
rawfilter %>% filter(filtered_2 == 99) %>% group_by(mes) %>% 
  summarise(n=n()) %>% 
  mutate(freq = round((n  / sum(n )*100),2)) %>% 
  ggplot(aes(x=as.factor(mes), y=n)) + 
  geom_bar(stat='identity') +
  geom_text(aes(label=freq, size=3, vjust=-.25)) + 
  theme_bw() + 
  theme(legend.position = 'none') + 
  xlab('month') + 
  ylab('# Images with Snow / Ice or Cloudy')
```

We select only data with high Good Quality, because shadow, ice or cloudy are mainly locate at winter months. 

```{r}
df <- rawfilter %>% 
  filter(filtered_2 == 90) %>% 
  select(doy, evi, ndvi, iv_malla_modi_id, pop, date, year, lat, long, summQA, qa_use, filtered, filtered_2, mes) 

df %>% group_by(mes) %>% 
  summarise(n=n()) %>% 
  mutate(freq = round((n/sum(n )*100),2)) %>% 
  ggplot(aes(x=as.factor(mes), y=n)) + 
  geom_bar(stat='identity') +
  geom_text(aes(label=freq, size=3, vjust=-.25)) + 
  theme_bw() + 
  theme(legend.position = 'none') + 
  xlab('month') + 
  ylab('# Images with Good Quality')
```

```{r}
ncomposites_year <- df %>% group_by(iv_malla_modi_id, year) %>% summarise(n=n()) 

ncomposites_year %>% ggplot(aes(x=n)) + 
  geom_histogram(stat='count') +
  xlab('# composites by year and pixel') + 
  ylab('# ')+
  theme_bw()
```


We do not apply a filter treshold, because we selected only the Good Data. 


# Prepare data of processed IV

### Get the composite of the images and the season
* See [Testa et al. 2014](https://www.researchgate.net/publication/262566793_Correcting_MODIS_16-day_composite_NDVI_time-series_with_actual_acquisition_dates)
* Use a [custom function](/script/R/getComposite.R)

```{r}
# Get leap years 
years <- unique(df$year)
ly <- years[lubridate::leap_year(years)]

# Two functions 
rd <- df %>% 
  mutate(m= lubridate::month(date),
         d= lubridate::day(date)) %>% 
  mutate(composite = ifelse(year %in% ly, 
                            getComposite_leap(m,d),
                            getComposite_nonleap(m,d))) %>% 
  mutate(season = ifelse(composite < 6, 'winter',
                   ifelse(composite < 12, 'spring',
                    ifelse(composite < 18, 'summer','autumn'))))
```

### Scale factor of the NDVI and EVI data 
```{r}
# Apply scale factor https://lpdaac.usgs.gov/dataset_discovery/modis/modis_products_table/mod13q1 
rd <- rd %>% 
  mutate(evi = evi * 0.0001,
         ndvi = ndvi * 0.0001) 
```



We created several datasets: 

### ***iv_composite*** 
iv by pixel and by composite (output as `./data/iv_composite.csv`). It contains the following fields: 

* `iv_malla_modi_id`: the identifier of the modis cell
* `year`
* `evi` or `ndvi`: the value of the EVI (or NDVI) for the composite 
* `date`: date of adquisition of the image
* `composite`: number of composite (23 by year)
* `long`: longitude coordinates
* `lat`: latitute coordinates 
* `pop`: numeric code of the *Q. pyrenaica* population
* `season`: 
    + `0` annual value
    + `1` spring value
    + `2` summer value 
    + `3` autumn value 
    + `4` winter value 
* `seasonF`: the season coded as factor 
* `summQA`: the summary Quality Assessment (see MODIS)
* `qa_use`: the usseful index (see QA MODIS)

### ***evi_mean***
evi mean by pixel and year (output as `./data/evi_mean.csv`). It contains the following fields:

* `iv_malla_modi_id`: the identifier of the modis cell
* `year`
* `evi`: mean value of evi for pixel *i* at year *j*
* `long`: longitude coordinates
* `lat`: latitute coordinates 
* `pop`: numeric code of the *Q. pyrenaica* population
* `n_composites`: number of composites used to computed the annual mean value of EVI (according to previously filtering)


### ***evi_seasonal*** and ***ndvi_seasonal***
* annual and seasonal evi by pixel (output as `./data/evi_atributes_all.csv`)
* annual and seasonal ndvi by pixel (output as `./data/ndvi_atributes_all.csv`)

These two dataframes have the following fields: 

* `iv_malla_modi_id`: the identifier of the modis cell
* `year`
* `evi` or `ndvi`: the value of the EVI (or NDVI) (cumulative value for each season)
* `season`: the season of cumulative evi:
    + `0` annual value
    + `1` spring value
    + `2` summer value 
    + `3` autumn value 
    + `4` winter value 
* `seasonF`: the season coded as factor 
* `long`: longitude coordinates
* `lat`: latitute coordinates 
* `pop`: numeric code of the *Q. pyrenaica* population 


#### Create dataframe with composites
```{r}
iv_composite <- rd %>% 
  dplyr::select(iv_malla_modi_id, evi, ndvi, pop, date, year, long, lat, composite, seasonF = season, summQA, qa_use)
```

#### Create EVI mean dataset
```{r}
evimean <- rd %>% 
  group_by(iv_malla_modi_id, year) %>%
  summarise(evi = mean(evi[evi >=0]),
            n_composites = length(year)) 

# Add coordinates and pob and other useful info 
aux_rd <- rd %>% dplyr::select(iv_malla_modi_id, long, lat, pop) %>%
  group_by(iv_malla_modi_id) %>% unique()

# Join dataframes 
evimean <- evimean %>% dplyr::inner_join(aux_rd, by="iv_malla_modi_id") 
```

####  Create seasonal dataframes of EVI and NDVI (integrate, EVI and NDVI sum)
* EVI
```{r}
# Create annual evi by pixel 
evi_annual <- rd %>% 
  group_by(iv_malla_modi_id, year) %>%
  summarise(evi = sum(evi[evi >=0])) %>%
  mutate(seasonF='annual', 
         season = 0)

# Create seasonal evi by pixel 
evi_season <- rd %>% 
  group_by(iv_malla_modi_id, year, season) %>%
  summarise(evi = sum(evi[evi >=0])) %>% 
  mutate(seasonF = season) %>% 
  mutate(season = ifelse(season == 'autumn', 3, 
                   ifelse(season == 'winter', 4, 
                    ifelse(season == 'spring', 1,2))))

evidf <- rbind(evi_annual, evi_season)

# Add coordinates and pob 
aux_rd <- rd %>% dplyr::select(iv_malla_modi_id, long, lat, pop) %>%
  group_by(iv_malla_modi_id) %>% unique()


# Join dataframes 
evidf <- evidf %>% dplyr::inner_join(aux_rd, by="iv_malla_modi_id") 
```

* NDVI 
```{r}
# Create annual ndvi by pixel 
ndvi_annual <- rd %>% 
  group_by(iv_malla_modi_id, year) %>%
  summarise(ndvi = sum(ndvi[ndvi >=0])) %>%
  mutate(seasonF='annual', 
         season = 0)

# Create seasonal ndvi by pixel 
ndvi_season <- rd %>% 
  group_by(iv_malla_modi_id, year, season) %>%
  summarise(ndvi = sum(ndvi[ndvi >=0])) %>% 
  mutate(seasonF = season) %>% 
  mutate(season = ifelse(season == 'autumn', 3, 
                   ifelse(season == 'winter', 4, 
                    ifelse(season == 'spring', 1,2))))

ndvidf <- rbind(ndvi_annual, ndvi_season)

# Join dataframes 
ndvidf <- ndvidf %>% dplyr::inner_join(aux_rd, by="iv_malla_modi_id")
```

### Export dataframes
```{r}
# Export dataframes 
write.csv(evimean, file=paste(di, "/data/evi_mean.csv", sep=""), row.names = FALSE)
write.csv(evidf, file=paste(di, "/data/evi_atributes_all.csv", sep=""), row.names = FALSE)
write.csv(ndvidf, file=paste(di, "/data/ndvi_atributes_all.csv", sep=""), row.names = FALSE)
write.csv(iv_composite, file=paste(di, "/data/iv_composite.csv", sep=""), row.names = FALSE)
```





```{r, echo=FALSE, eval=FALSE}
# * Now we convert data of EVI, NDVI according to our ***filter criteria***: 
#  * we remove the year value of a pixel if the pixel has bad quality in more than 4 composites in a year (4/23 = 17.39%; we retained 82.6 %) 
#  * we remove a pixel of the series if the pixel has bad quality for more 3 years (3/16 = 18.75 %; we retained 81.25 %)

df <- rawfilter %>% 
  filter(year != 2016) %>% 
  select(doy, evi, ndvi, iv_malla_modi_id, pop, date, year, lat, long, summQA, qa_use, filtered, filtered_2) %>% 
  mutate(evi_f = ifelse(filtered_2 == 90, evi, NA),
         ndvi_f = ifelse(filtered_2 == 90, ndvi,NA), 
         mes = lubridate::month(date))



# Create counters 
pixeles <- unique(df$iv_malla_modi_id)
years <- unique(df$year)

# Dataframe for output
filter_pixel_year <- data.frame()

for (i in pixeles){ 
  # Create a subset of pixel of interest   
  df_pixel <- df %>% filter(iv_malla_modi_id == i) 
  
  # Create empty dataframe 
  filter_pixel_year_aux <- data.frame()
  
  for (j in years){ 
    # empty dataframe 
    out_aux <- data.frame()
    
    # Create a dataframe for year "j"
    df_pixel_year <- df_pixel %>% filter(year == j) 
    
    # Get numbers of composites by year 
    n_composites <- df_pixel_year %>% count() 
    
    # How many composites are marked as "bad data" 
    bad_composites <- sum(is.na(df_pixel_year$evi_f))
    
    # Treshold composites
    # For year 2000 is 3; for other year is 4 
    tc <- ifelse(j == 2000, 4, 5)
    
    # Output 
    status <- ifelse(bad_composites > tc, 'Bad year', 'Ok') 
    out_aux <- cbind(i, y, status)
    
    # status <- ifelse(bad_composites > tc, 'Bad year', 'Ok') 
    # out_aux$iv_malla_modi_id <- i 
    # out_aux$status <- ifelse(bad_composites > tc, 'Bad year', 'Ok') 
    #   
    #   <- cbind(iv_malla_modi_id = as.numeric(as.character(i)), 
    #              year=as.numeric(as.character(j)), 
    #              status)
    
    # Rbinds
    filter_pixel_year_aux <- rbind(filter_pixel_year_aux, out_aux)
    }
  
  # Rbinds
  filter_pixel_year <- rbind(filter_pixel_year, filter_pixel_year_aux)
} 


filter_pixel_year <- filter_pixel_year %>% 
  mutate(year = as.numeric(as.character(y)), 
         iv_malla_modi_id = as.numeric(as.character(i))) %>% 
  select(year, iv_malla_modi_id, status)


filter_pixel_year %>% 
  group_by(iv_malla_modi_id, status) %>% 
  summarise(n = n())

```




















